{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text prepration in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('/Users/atousa/Desktop/McMaster/BDA-102/week2-NLTK/Canada_wiki.txt')\n",
    "raw_data=f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Canada (/ˈkænədə/ (About this sound listen); French: [kanadɑ]) is a country in the northern part of North America. Its ten provinces and three territories extend from the Atlantic to the Pacific and northward into the Arctic Ocean, covering 9.98 million square kilometres (3.85 million square miles),'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=raw_data.replace(\"(/ˈkænədə/ (About this sound listen); French: [kanadɑ])\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Canada  is a country in the northern part of North America. Its ten provinces and three territories extend from the Atlantic to the Pacific and northward into the Arctic Ocean, covering 9.98 million square kilometres (3.85 million square miles), making it the world's second-largest country by total \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "#Alternatives for word tokenizer\n",
    "#from nltk.tokenize import TreebankWordTokenizer\n",
    "#from nltk.tokenize import WordPunctTokenizer\n",
    "#from nltk.tokenize import regexp_tokenize\n",
    "#regexp_tokenize(data,[\\w']+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent_List=sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canada  is a country in the northern part of North America.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Sent_List[0])\n",
    "len(Sent_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_List=word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Canada', 'is', 'a', 'country', 'in', 'the', 'northern', 'part', 'of', 'North', 'America', '.', 'Its', 'ten', 'provinces', 'and', 'three', 'territories', 'extend', 'from', 'the', 'Atlantic', 'to', 'the', 'Pacific', 'and', 'northward', 'into', 'the', 'Arctic', 'Ocean', ',', 'covering', '9.98', 'million', 'square', 'kilometres', '(', '3.85', 'million', 'square', 'miles', ')', ',', 'making', 'it', 'the', 'world', \"'s\", 'second-largest', 'country', 'by', 'total', 'area', 'and', 'the', 'fourth-largest', 'country', 'by', 'land', 'area', '.', 'Canada', \"'s\", 'southern', 'border', 'with', 'the', 'United', 'States', 'is', 'the', 'world', \"'s\", 'longest', 'bi-national', 'land', 'border', '.', 'The', 'majority', 'of', 'the', 'country', 'has', 'a', 'cold', 'or', 'severely', 'cold', 'winter', 'climate', ',', 'but', 'southerly', 'areas', 'are', 'warm', 'in', 'summer']\n"
     ]
    }
   ],
   "source": [
    "len(world_List)\n",
    "print(world_List[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visuaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent_len=[]\n",
    "for i in Sent_List:\n",
    "    Sent_len.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.01411632, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00705816, 0.        , 0.        , 0.00705816, 0.02117448,\n",
       "        0.01411632, 0.        , 0.        , 0.02823264, 0.01411632,\n",
       "        0.02117448, 0.00705816, 0.        , 0.00705816, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00705816, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00705816]),\n",
       " array([ 57.  ,  63.44,  69.88,  76.32,  82.76,  89.2 ,  95.64, 102.08,\n",
       "        108.52, 114.96, 121.4 , 127.84, 134.28, 140.72, 147.16, 153.6 ,\n",
       "        160.04, 166.48, 172.92, 179.36, 185.8 , 192.24, 198.68, 205.12,\n",
       "        211.56, 218.  , 224.44, 230.88, 237.32, 243.76, 250.2 , 256.64,\n",
       "        263.08, 269.52, 275.96, 282.4 , 288.84, 295.28, 301.72, 308.16,\n",
       "        314.6 , 321.04, 327.48, 333.92, 340.36, 346.8 , 353.24, 359.68,\n",
       "        366.12, 372.56, 379.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Sent_len, normed=True, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"weren't\", \"it's\", 'few', \"hasn't\", 'ma', 'of', 'their', 'nor', 'below', 'down', 'myself', 'above', 'my', \"you'd\", 'between', 'wouldn', 'an', 'then', 'he', 'until', 'such', 'those', 'won', 'have', 'what', 'hadn', 'are', 'we', 'yourself', 'itself', 'should', 'isn', \"wasn't\", 'at', 'once', 'that', 'there', 'before', \"doesn't\", 'in', 'can', 'himself', 'i', 'am', 'if', 'were', \"you'll\", 'shouldn', 'they', \"hadn't\", 'ain', 'both', 'this', 'is', 'all', 'by', 'you', 're', 'it', \"wouldn't\", 'wasn', 'further', \"couldn't\", 'mustn', 'most', 'into', 'here', 'aren', 'on', 'who', 'did', 'ourselves', 'needn', 'had', 'each', \"shan't\", 'me', 'from', 'been', 'when', 'why', 'her', \"you're\", \"shouldn't\", 'don', 'mightn', 'own', 'haven', 'through', 'which', 'theirs', 'weren', 'some', 'during', 'him', 'up', 'now', 'doing', 't', 'very', \"you've\", 'your', 'for', 'yours', \"she's\", 'having', 'too', 'no', 'more', 'against', 'shan', 'do', \"won't\", 'but', 's', 'd', 'hasn', 'hers', 'just', 'only', 've', 'o', 'or', 'about', 'ours', 'to', 'over', 'the', 'our', 'under', \"didn't\", 'because', 'with', \"should've\", 'was', 'does', 'll', 'so', 'whom', 'them', \"don't\", 'other', \"mightn't\", \"that'll\", 'herself', 'while', \"aren't\", 'couldn', 'and', 'as', \"isn't\", 'again', 'will', 'she', 'be', 'themselves', 'has', \"mustn't\", 'his', 'how', 'm', 'same', 'than', 'didn', 'doesn', 'after', 'these', 'being', \"needn't\", 'off', 'a', 'not', 'where', 'any', \"haven't\", 'yourselves', 'out', 'its', 'y'}\n"
     ]
    }
   ],
   "source": [
    "print(Stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_word=[w for w in world_List if not w in Stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the very basics of it, the major difference between the porter and lancaster stemming algorithms is that the lancaster stemmer is significantly more aggressive than the porter stemmer. \n",
    "\n",
    "Porter: porter is a rule based stemmer. Most commonly used stemmer with one of the most gentle stemmers. \n",
    "\n",
    "Porter2 Stemmer: It is very similar to \"Porter Stemmer\" but with slightly improved rules. \n",
    "\n",
    "Lancaster: Very aggressive stemming algorithm, sometimes to a fault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "#from stemming.porter2 import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS=PorterStemmer()\n",
    "LS=LancasterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stem_words=[PS.stem(w) for w in filtered_word]\n",
    "Stem_words2=[LS.stem(w) for w in filtered_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country',\n",
       " 'northern',\n",
       " 'part',\n",
       " 'North',\n",
       " 'America',\n",
       " '.',\n",
       " 'Its',\n",
       " 'ten',\n",
       " 'provinces']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_word[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['countri',\n",
       " 'northern',\n",
       " 'part',\n",
       " 'north',\n",
       " 'america',\n",
       " '.',\n",
       " 'it',\n",
       " 'ten',\n",
       " 'provinc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stem_words[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'northern', 'part', 'nor', 'americ', '.', 'it', 'ten', 'provint']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stem_words2[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "rs=RegexpStemmer('ing')\n",
    "Stem_words3=[rs.stem(w) for w in filtered_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/atousa/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "tagged=nltk.pos_tag(filtered_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Canada', 'NNP'),\n",
       " ('country', 'NN'),\n",
       " ('northern', 'JJ'),\n",
       " ('part', 'NN'),\n",
       " ('North', 'NNP'),\n",
       " ('America', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Its', 'PRP$'),\n",
       " ('ten', 'JJ'),\n",
       " ('provinces', 'NNS')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "source": [
    "%xmode verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the grammer rule\n",
    "#adverb+verb+Proper noun+noun/? can be exist or not/* zero or more\n",
    "n_gram=r\"n_gram:{<RB>*<NN>*<NNP>+<NN>*}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_parser=RegexpParser(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chunk=n_gram_parser.parse(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_gram Canada/NNP country/NN)\n",
      "---------\n",
      "('northern', 'JJ')\n",
      "---------\n",
      "(n_gram part/NN North/NNP America/NNP)\n",
      "---------\n",
      "('.', '.')\n",
      "---------\n",
      "('Its', 'PRP$')\n",
      "---------\n",
      "('ten', 'JJ')\n",
      "---------\n",
      "('provinces', 'NNS')\n",
      "---------\n",
      "('three', 'CD')\n",
      "---------\n",
      "('territories', 'NNS')\n",
      "---------\n",
      "('extend', 'VBP')\n",
      "---------\n",
      "(n_gram Atlantic/NNP Pacific/NNP)\n",
      "---------\n",
      "(n_gram northward/RB Arctic/NNP Ocean/NNP)\n",
      "---------\n",
      "(',', ',')\n",
      "---------\n",
      "('covering', 'VBG')\n",
      "---------\n",
      "('9.98', 'CD')\n",
      "---------\n",
      "('million', 'CD')\n",
      "---------\n",
      "('square', 'JJ')\n",
      "---------\n",
      "('kilometres', 'NNS')\n",
      "---------\n",
      "('(', '(')\n",
      "---------\n",
      "('3.85', 'CD')\n",
      "---------\n",
      "('million', 'CD')\n",
      "---------\n",
      "('square', 'JJ')\n",
      "---------\n",
      "('miles', 'NNS')\n",
      "---------\n",
      "(')', ')')\n",
      "---------\n",
      "(',', ',')\n",
      "---------\n",
      "('making', 'VBG')\n",
      "---------\n",
      "('world', 'NN')\n",
      "---------\n",
      "(\"'s\", 'POS')\n",
      "---------\n",
      "('second-largest', 'JJ')\n",
      "---------\n",
      "('country', 'NN')\n",
      "---------\n",
      "('total', 'JJ')\n",
      "---------\n",
      "('area', 'NN')\n",
      "---------\n",
      "('fourth-largest', 'JJ')\n",
      "---------\n",
      "('country', 'NN')\n",
      "---------\n",
      "('land', 'NN')\n",
      "---------\n",
      "('area', 'NN')\n",
      "---------\n",
      "('.', '.')\n",
      "---------\n",
      "(n_gram Canada/NNP)\n",
      "---------\n",
      "(\"'s\", 'POS')\n",
      "---------\n",
      "('southern', 'JJ')\n",
      "---------\n",
      "(n_gram border/NN United/NNP)\n",
      "---------\n",
      "('States', 'NNPS')\n",
      "---------\n",
      "('world', 'NN')\n",
      "---------\n",
      "(\"'s\", 'POS')\n",
      "---------\n",
      "('longest', 'JJS')\n",
      "---------\n",
      "('bi-national', 'JJ')\n",
      "---------\n",
      "('land', 'NN')\n",
      "---------\n",
      "('border', 'NN')\n",
      "---------\n",
      "('.', '.')\n",
      "---------\n",
      "('The', 'DT')\n",
      "---------\n",
      "('majority', 'NN')\n",
      "---------\n",
      "('country', 'NN')\n",
      "---------\n",
      "('cold', 'VBD')\n",
      "---------\n",
      "('severely', 'RB')\n",
      "---------\n",
      "('cold', 'JJ')\n",
      "---------\n",
      "('winter', 'NN')\n",
      "---------\n",
      "('climate', 'NN')\n",
      "---------\n",
      "(',', ',')\n",
      "---------\n",
      "('southerly', 'RB')\n",
      "---------\n",
      "('areas', 'NNS')\n",
      "---------\n",
      "('warm', 'VBP')\n",
      "---------\n",
      "('summer', 'NN')\n",
      "---------\n",
      "('.', '.')\n",
      "---------\n",
      "(n_gram Canada/NNP)\n",
      "---------\n",
      "('sparsely', 'RB')\n",
      "---------\n",
      "('populated', 'VBD')\n",
      "---------\n",
      "(',', ',')\n",
      "---------\n",
      "('majority', 'NN')\n",
      "---------\n",
      "('land', 'NN')\n",
      "---------\n",
      "('territory', 'NN')\n",
      "---------\n",
      "('dominated', 'VBN')\n",
      "---------\n",
      "('forest', 'JJS')\n",
      "---------\n",
      "(n_gram tundra/NN Rocky/NNP Mountains/NNP)\n",
      "---------\n",
      "('.', '.')\n",
      "---------\n",
      "('It', 'PRP')\n",
      "---------\n",
      "('highly', 'RB')\n",
      "---------\n",
      "('urbanized', 'VBD')\n",
      "---------\n",
      "('82', 'CD')\n",
      "---------\n",
      "('per', 'IN')\n",
      "---------\n",
      "('cent', 'NN')\n",
      "---------\n",
      "('35.15', 'CD')\n",
      "---------\n",
      "('million', 'CD')\n",
      "---------\n",
      "('people', 'NNS')\n",
      "---------\n",
      "('concentrated', 'JJ')\n",
      "---------\n",
      "('large', 'JJ')\n",
      "---------\n",
      "('medium-sized', 'JJ')\n",
      "---------\n",
      "('cities', 'NNS')\n",
      "---------\n",
      "(',', ',')\n",
      "---------\n",
      "('many', 'JJ')\n",
      "---------\n",
      "('near', 'IN')\n",
      "---------\n",
      "('southern', 'JJ')\n",
      "---------\n",
      "('border', 'NN')\n",
      "---------\n",
      "('.', '.')\n",
      "---------\n",
      "('Its', 'PRP$')\n",
      "---------\n",
      "(n_gram capital/NN Ottawa/NNP)\n",
      "---------\n",
      "(',', ',')\n",
      "---------\n",
      "('five', 'CD')\n",
      "---------\n",
      "('largest', 'JJS')\n",
      "---------\n",
      "('metropolitan', 'NN')\n",
      "---------\n",
      "('areas', 'NNS')\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "#n_chunk.draw()\n",
    "for i in range(0,100,1):\n",
    "    print(n_chunk[i])\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.metrics import TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 'Canada'),\n",
       " ('areas', 'are'),\n",
       " ('world', \"'s\"),\n",
       " ('million', 'square'),\n",
       " ('southern', 'border'),\n",
       " ('ten', 'provinces'),\n",
       " ('three', 'territories'),\n",
       " ('Canada', 'is'),\n",
       " ('North', 'America'),\n",
       " ('United', 'States')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of the words to be printed\n",
    "n=10\n",
    "finder=BigramCollocationFinder.from_words(world_List)\n",
    "finder.nbest(BigramAssocMeasures.likelihood_ratio,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 'Canada', 'is'),\n",
       " ('Canada', 'is', 'a'),\n",
       " ('.', 'It', 'is'),\n",
       " ('the', 'world', \"'s\"),\n",
       " ('.', 'Canada', 'achieved'),\n",
       " ('provinces', 'and', 'three'),\n",
       " ('ten', 'provinces', 'and'),\n",
       " ('the', 'United', 'States'),\n",
       " ('.', 'Canada', \"'s\"),\n",
       " ('areas', 'are', 'Toronto')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder=TrigramCollocationFinder.from_words(world_List)\n",
    "finder.nbest(TrigramAssocMeasures.likelihood_ratio,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/atousa/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjective:pos=\"a\"\n",
    "# Adverb:pos=\"r\"\n",
    "# Noun:pos=\"n\"\n",
    "# Verb:pos=\"v\"\n",
    "wnl.lemmatize(\"better\",pos=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/nltk_data/\n",
    "         Chunker,\n",
    "         Corpora,\n",
    "         Grammer,\n",
    "         Sentiment,\n",
    "         Stemmer,\n",
    "         Tagger,\n",
    "         Tockenizer,\n",
    "\n",
    "nltk_data/Corpora/\n",
    "          Wordnet,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------similarity-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1=\"win\"\n",
    "word2=\"award\"\n",
    "word3=\"cat\"\n",
    "synarray1=wordnet.synsets(word1)\n",
    "synarray2=wordnet.synsets(word2)\n",
    "synarray3=wordnet.synsets(word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('win.n.01'),\n",
       " Synset('winnings.n.01'),\n",
       " Synset('win.v.01'),\n",
       " Synset('acquire.v.05'),\n",
       " Synset('gain.v.05'),\n",
       " Synset('succeed.v.01')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synarray1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('award.n.01'),\n",
       " Synset('award.n.02'),\n",
       " Synset('prize.n.01'),\n",
       " Synset('award.v.01'),\n",
       " Synset('award.v.02')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synarray2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cat.n.01'),\n",
       " Synset('guy.n.01'),\n",
       " Synset('cat.n.03'),\n",
       " Synset('kat.n.01'),\n",
       " Synset('cat-o'-nine-tails.n.01'),\n",
       " Synset('caterpillar.n.02'),\n",
       " Synset('big_cat.n.01'),\n",
       " Synset('computerized_tomography.n.01'),\n",
       " Synset('cat.v.01'),\n",
       " Synset('vomit.v.01')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synarray3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=synarray1[3]\n",
    "w2=synarray2[3]\n",
    "w3=synarray3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"win something through one's efforts\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypernym: More abstract, it goes one category above the current level of defenition, \n",
    "\n",
    "Hyponym: More detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('cozen.v.03')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('get.v.01')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('acquire.v.05.acquire'),\n",
       " Lemma('acquire.v.05.win'),\n",
       " Lemma('acquire.v.05.gain')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'win'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.lemmas()[1].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wu - Palmer Similarity\n",
    "# how to words are similar\n",
    "w1.wup_similarity(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many path exist between\n",
    "w1.path_similarity(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.258096538021482"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leacok chodorow\n",
    "w1.lch_similarity(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.wup_similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.wup_similarity(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.path_similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0608719606852628"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.lch_similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=w1.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('get.v.01')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shortest_path_distance(ref[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----Regular Expression-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex=re.compile(r'don\\'t')\n",
    "txt=\"I don't go to school\"\n",
    "sst=regex.sub(\"do not\",txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not go to school'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex=re.compile(r'\\w{3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123g_***'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.sub(r'123','biig_***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='https://www.wikidata.org/w/api.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='J. K. Rowling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param={'action':'wbsearchentities','format':'json','search':query,'language':'en'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get(path,params=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'searchinfo': {'search': 'J. K. Rowling'},\n",
       " 'search': [{'repository': '',\n",
       "   'id': 'Q34660',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q34660',\n",
       "   'title': 'Q34660',\n",
       "   'pageid': 37368,\n",
       "   'url': '//www.wikidata.org/wiki/Q34660',\n",
       "   'label': 'J. K. Rowling',\n",
       "   'description': 'English novelist',\n",
       "   'match': {'type': 'label', 'language': 'en', 'text': 'J. K. Rowling'}},\n",
       "  {'repository': '',\n",
       "   'id': 'Q5410773',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q5410773',\n",
       "   'title': 'Q5410773',\n",
       "   'pageid': 5175022,\n",
       "   'url': '//www.wikidata.org/wiki/Q5410773',\n",
       "   'label': 'Harry Potter universe',\n",
       "   'description': 'fictional universe created by J. K. Rowling',\n",
       "   'match': {'type': 'alias',\n",
       "    'language': 'en',\n",
       "    'text': \"J. K. Rowling's Wizarding World\"},\n",
       "   'aliases': [\"J. K. Rowling's Wizarding World\"]},\n",
       "  {'repository': '',\n",
       "   'id': 'Q57918468',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q57918468',\n",
       "   'title': 'Q57918468',\n",
       "   'pageid': 57833012,\n",
       "   'url': '//www.wikidata.org/wiki/Q57918468',\n",
       "   'label': 'J. K. Rowling: Harry Potter',\n",
       "   'description': 'article',\n",
       "   'match': {'type': 'label',\n",
       "    'language': 'en',\n",
       "    'text': 'J. K. Rowling: Harry Potter'}},\n",
       "  {'repository': '',\n",
       "   'id': 'Q43361',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q43361',\n",
       "   'title': 'Q43361',\n",
       "   'pageid': 45569,\n",
       "   'url': '//www.wikidata.org/wiki/Q43361',\n",
       "   'label': \"Harry Potter and the Philosopher's Stone\",\n",
       "   'description': 'fantasy novel by J. K. Rowling',\n",
       "   'match': {'type': 'alias',\n",
       "    'language': 'sv',\n",
       "    'text': 'J. K. Rowling: Harry Potter och de vises sten'},\n",
       "   'aliases': ['J. K. Rowling: Harry Potter och de vises sten']},\n",
       "  {'repository': '',\n",
       "   'id': 'Q46751',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q46751',\n",
       "   'title': 'Q46751',\n",
       "   'pageid': 48889,\n",
       "   'url': '//www.wikidata.org/wiki/Q46751',\n",
       "   'label': 'Harry Potter and the Goblet of Fire',\n",
       "   'description': 'fantasy novel by J. K. Rowling',\n",
       "   'match': {'type': 'alias',\n",
       "    'language': 'sv',\n",
       "    'text': 'J. K. Rowling: Harry Potter och Den Flammande Bägaren'},\n",
       "   'aliases': ['J. K. Rowling: Harry Potter och Den Flammande Bägaren']},\n",
       "  {'repository': '',\n",
       "   'id': 'Q80817',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q80817',\n",
       "   'title': 'Q80817',\n",
       "   'pageid': 83297,\n",
       "   'url': '//www.wikidata.org/wiki/Q80817',\n",
       "   'label': 'Harry Potter and the Order of the Phoenix',\n",
       "   'description': 'fantasy novel by J. K. Rowling',\n",
       "   'match': {'type': 'alias',\n",
       "    'language': 'sv',\n",
       "    'text': 'J. K. Rowling: Harry Potter och Fenixorden'},\n",
       "   'aliases': ['J. K. Rowling: Harry Potter och Fenixorden']},\n",
       "  {'repository': '',\n",
       "   'id': 'Q17895706',\n",
       "   'concepturi': 'http://www.wikidata.org/entity/Q17895706',\n",
       "   'title': 'Q17895706',\n",
       "   'pageid': 19463867,\n",
       "   'url': '//www.wikidata.org/wiki/Q17895706',\n",
       "   'label': 'J. K. Rowling pode escrever oitavo livro de Harry Potter',\n",
       "   'description': 'Wikinews article',\n",
       "   'match': {'type': 'label',\n",
       "    'language': 'pt',\n",
       "    'text': 'J. K. Rowling pode escrever oitavo livro de Harry Potter'}}],\n",
       " 'search-continue': 7,\n",
       " 'success': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'45th and current president of the United States'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['search'][0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikidata-sparql query service\n",
    "# https://query.wikidata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Johann Sebastian Bach.\n",
    "#SELECT ?item ?itemLabel \n",
    "#WHERE\n",
    "#{\n",
    "#  ?item educated at University of Edinburgh.\n",
    "#}\n",
    "\n",
    "#Wikidata, items and properties are not identified by human-readable names like “father” (property) or “Bach” (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The SPARQL service makes use of two key namespaces: \n",
    "#wd: , which is where items live\n",
    "#wdt: for elements that serve as a simplified representation of properties, directly connecting items and values. \n",
    "#The 't' in wdt: stands for \"truthy\".\n",
    "\n",
    "#SELECT ?item ?itemLabel \n",
    "#WHERE \n",
    "#{\n",
    "#  ?item wdt:P69 wd:Q160302\n",
    "#  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "#}\n",
    "#you can find the code by enterring #control+space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
